			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Nithi Jangidi      <nithired@buffalo.edu>
Sai Akash Sunku    <saiakash@buffalo.edu>
Pavanth Nimmagadda <pavanthn@buffalo.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h:
struct thread {
    int64_t wake_time;   /*The time at which the thread should wake up */
};

Global static variables in timer.c: 
static struct list sleeping_threads; /* List of threads that are currently sleeping, sorted by wake-up time. */

Purpose: The `wake_time` field stores the tick count when a thread should wake up. The `sleeping_threads` list holds all sleeping threads in order of their wake-up time. 

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Call to timer_sleep():
    1. When a thread calls timer_sleep(), it first calculates how long it should sleep by determining the current number of timer ticks and adding the requested number of sleep ticks. This gives the thread a wake-up time (i.e., the number of ticks after which it should be woken up).
    2. The thread is then inserted into the global sleeping_threads list. This list stores all the threads that are currently sleeping, and it is sorted based on the wake_time of each thread. The list_insert_ordered() function is used to maintain the list in an ascending order, so the thread with the earliest wake-up time is always at the front of the list.
    3. After inserting the thread into the list, timer_sleep() blocks the thread by calling thread_block(). This prevents the thread from being scheduled to run until it is unblocked by the timer interrupt handler.

Timer Interrupt Handler (timer_interrupt()):
    1. The timer interrupt handler is invoked automatically at each timer tick. During each tick, the handler increments the system's tick count and checks the sleeping_threads list to see if any thread's wake-up time has arrived.
    2. The handler checks the first thread in the sleeping_threads list (since it is sorted by wake-up time) to see if the current time (ticks) is greater than or equal to the thread's wake time.
    3.If the wake-up time has been reached, the thread is removed from the list and unblocked by calling thread_unblock(). This allows the thread to resume execution during the next scheduling cycle.
    4. The handler continues checking the list until it encounters a thread whose wake-up time has not yet been reached (because the list is sorted, no further threads need to be checked after that).

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
To minimize time spent in the timer interrupt handler, only the first thread in the sleeping_threads list (the one with the earliest wake-up time) is checked.
Once its wake-up time has passed, the handler removes the thread from the list and unblocks it.
The list is maintained in sorted order, so checking only the front of the list ensures minimal work is done during each interrupt.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
Race conditions are avoided in timer_sleep() by disabling interrupts before modifying the sleeping_threads list and calling thread_block().
This ensures that no interrupt can occur while the thread is being added to the list or being blocked.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
When a timer interrupt occurs during timer_sleep(), race conditions are avoided by also disabling interrupts while accessing and modifying the sleeping_threads list in timer_interrupt().
This ensures that no simultaneous modifications can happen to the list by other threads or interrupts.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This design was chosen because it avoids busy-waiting and uses efficient thread management (blocking/unblocking), which improves system performance by allowing other threads to run while a thread is sleeping.
Using an ordered list minimizes the work done in the timer interrupt handler, making this approach more efficient than iterating over all sleeping threads in every interrupt.
Alternative designs, such as using semaphores for each thread, were considered, but the list-based approach with interrupts disabled is simpler, avoids unnecessary context switches, and is more efficient in handling multiple sleeping threads.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

// In struct thread (thread.h)
int real_priority;        // The original priority of the thread (before any donation). 
struct lock *current_lock; // The lock the thread is currently trying to acquire.
struct list locks_held;    // List of locks held by this thread.

// In struct lock (synch.h)
int max_priority;         // The highest priority among threads waiting for this lock.

// In struct semaphore_elem (synch.c)
int priority;             // Priority of the thread waiting on this semaphore.

// Global Variables (thread.c)
static struct list ready_list;  // List of threads ready to run.


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Thread structure (struct thread):

Each thread maintains a waiting_for_lock pointer to indicate the lock it is waiting for.
The locks_held list stores the locks currently held by the thread.
Lock structure (struct lock):

Each lock stores the max_priority of the highest-priority thread waiting on it.
Lists for synchronization:

The semaphore.waiters list inside a lock stores threads waiting for the lock, ordered by priority.
These structures allow nested donation to propagate through multiple locks and threads.

+--------------------+     +--------------------+     +--------------------+
|   Thread A         |     |   Thread B         |     |   Thread C         |
|   Priority: 63     |     |   Priority: 31     |     |   Priority: 15     |
+--------------------+     +--------------------+     +--------------------+
        |                         |                         |
        |  tries to acquire       |  tries to acquire       |
        |  Lock 1                 |  Lock 2                 |
        v                         v                         v
+--------------------+     +--------------------+     +--------------------+
|   Lock 1           |     |   Lock 2           |     |   Held by Thread C  |
|   Held by Thread B |     |   Held by Thread C |     |                    |
+--------------------+     +--------------------+     +--------------------+

Thread A (priority 63) tries to acquire Lock 1, held by Thread B (priority 31).
Thread B's priority is boosted to 63 through priority donation.
Thread B (now priority 63) tries to acquire Lock 2, held by Thread C (priority 15).
Thread C's priority is also boosted to 63 through nested donation.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
Wait List Management:
Each semaphore maintains a list of waiting threads in the waiters list.
When a thread waits on a semaphore, it is inserted into this list in priority order
This ensures that the thread with the highest priority is always at the end of the list (ready to be popped).

Unblocking the Highest Priority Thread:
When sema_up() is called, the highest-priority thread is chosen.
The highest-priority thread is then unblocked and added to the ready list.
This ensures that the highest-priority thread is the first to wake up.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When lock_acquire() causes priority donation, the following sequence occurs:
Current thread marks the lock in its current_lock field, checks if lock is held
If held, compares priorities - if current thread's priority is higher, starts donation chain
Follows chain through current_lock pointers, updating each holder's priority to donated value
Continues chain if lock holder is waiting on another lock (nested donation), stops when no more locks
When locks release, priorities are recalculated based on remaining held locks and original priority

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When lock_release() is called on a lock with a waiting higher-priority thread:
Lock is removed from the releasing thread's locks_held list
Thread's priority is restored to highest remaining donated priority or original priority
Lock's holder is set to NULL and waiting thread is unblocked from semaphore
Unblocked higher-priority thread becomes ready and gets scheduled due to thread_yield

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
Potential Race:
A thread's priority could change while it is blocked on a lock, and priority donation could happen
simultaneously, causing an inconsistent state.

Solution:
The interrupts are disabled during priority updates to prevent race conditions.
Locks cannot be used to avoid this race since priority changes and donations can occur within interrupt handlers.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
Chosen Design:
Priority donation ensures that higher-priority threads do not get blocked indefinitely by lower-priority threads, preventing priority inversion.
The use of ordered lists ensures that the highest-priority thread always gets unblocked first.
Advantages:

Efficiency: This design avoids complex data structures, making it easier to manage locks and semaphores.
Scalability: Handles nested donations across multiple locks seamlessly.
Simplicity: Integrates well with existing synchronization primitives in Pintos.

Alternative Considered:

An explicit dependency graph to track priority inheritance was considered, but it was rejected because it introduced
significant complexity and overhead.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


recent_cpu (struct thread) : Stores the recent CPU usage by the thread, used in the MLFQ scheduler to adjust priority (in fixed-point arithmetic).

nice (struct thread): Represents how "nice" the thread is. A higher value lowers the threadâ€™s priority, influencing scheduling decisions.

load_avg (global/static variable): Stores the system-wide load average, reflecting the average number of ready threads over time.

F (macro): Defines the scaling factor for 17.14 fixed-point arithmetic (2^14), which simplifies floating-point operations using integers.

Fixed-point arithmetic macros:

INT_TO_FP(n): Converts an integer to a fixed-point value.
FP_TO_INT_ZERO(x): Converts a fixed-point value to an integer by truncation.
FP_TO_INT_NEAREST(x): Converts a fixed-point value to the nearest integer.
MUL_FP(x, y): Multiplies two fixed-point numbers.
DIV_FP(x, y): Divides one fixed-point number by another.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

Priority = PRI_MAX(63) - (recent_cpu/4) - (nice*2)
recent_cpu is in fixed-point format and is incremented by F(1<<14) each tick for the running thread
Priorities are recalculated every 4 ticks

Initial state:

All threads start with recent_cpu = 0
Thread A: nice = 0
Thread B: nice = 1
Thread C: nice = 2

Here's the table:
Timer  Recent_CPU    Priority   Recent_CPU    Priority   Recent_CPU    Priority   Thread
Ticks    A             A          B            B          C            C         to run
-----  ----------  ----------  -----------  ----------  -----------  ----------  --------
 0      0            63         0            61         0            59         A
 4      4F           62         0            61         0            59         A
 8      8F           61         0            61         0            59         A
12      12F          60         0            61         0            59         B
16      12F          60         4F           60         0            59         B
20      12F          60         8F           59         0            59         A
24      16F          59         8F           59         0            59         A
28      16F          59         12F          58         0            59         C

F represents the fixed-point factor (1<<14).
For each 4 ticks:
The running thread's recent_cpu increases by 4F
The priority calculation is recalculated for all threads
The thread with highest priority runs next
If priorities are equal, they would be scheduled round-robin

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
The main ambiguity is how to handle priority ties, which my code resolves through the ready list
ordering using list_insert_ordered() with compare_threads_by_priority(). Another ambiguity is fixed-point rounding,
which my code handles consistently by using FP_TO_INT_ZERO for priority calculations, always rounding toward zero. These both match
the scheduler's actual behavior, with priority recalculations happening exactly every 4 ticks for all threads simultaneously.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
In my implementation, we handles heavy computations outside interrupt context where possible. 
For example, thread priority updates and comparisons happen in thread_update_priority and compare_threads_by_priority. 
The interrupt context (thread_tick) only handles essential bookkeeping like incrementing recent_cpu and checking if it's time to update 
priorities/load_avg. By minimizing work in interrupt context, the system can quickly respond to new interrupts, improving overall system responsiveness
and performance.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages:
Clear fixed-point arithmetic implementation with well-defined macros, making calculations precise and readable
Efficient priority management using list_insert_ordered() to maintain sorted ready list
Split load between interrupt and non-interrupt contexts appropriately

Disadvantages:
Using thread_foreach() for priority updates may be inefficient for large number of threads since it updates all threads, even blocked ones
Fixed-point arithmetic could potentially overflow with very large values
No caching of priority calculations, recalculating every 4 ticks even if recent_cpu/nice haven't changed

Potential improvements:
Implement a priority queue data structure for better scheduling efficiency
Add overflow checking for fixed-point calculations


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Using macros for fixed-point arithmetic ensures code clarity and minimizes errors. The abstraction makes the implementation reusable and reduces the chance of arithmetic mistakes.

An abstraction layer (like macros) simplifies complex operations and keeps the code readable.
Fixed-point math is prone to rounding issues, so a consistent abstraction reduces the chance of inconsistencies.

Macros avoid the overhead of function calls and keep critical arithmetic operations fast, which is crucial for real-time systems like schedulers.



			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?